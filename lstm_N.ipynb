{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_N.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOdo7Bds2zLJ8FpVXBlJB/e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sathyakumarnsk/action_classifier/blob/master/lstm_N.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnezd7OCSsyn"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import json\n",
        "import numpy as np\n",
        "#from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Input\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers import LeakyReLU"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICNw9rAmSxe8"
      },
      "source": [
        "#Loading in data\n",
        "data_path = \"./data_humans.json\"\n",
        "#Load data\n",
        "with open(data_path, \"r\") as fp:\n",
        "    data = json.load(fp)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7Fnl_S7TJWy"
      },
      "source": [
        "# data.keys()\n",
        "labels=data['metadata']['all labels in loaded order']\n",
        "# data['metadata'].keys()\n",
        "#data['dataperclass'].keys()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOhtYTjhTMAs",
        "outputId": "5c3fa8dc-db73-4724-8934-71b8de4a0313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "X=list(); Y=list()\n",
        "C_x=list();C_y=list()\n",
        "for i,c in enumerate(labels):\n",
        "  print(c)\n",
        "  skel_class=data['dataperclass'][c]['skelsinfo_list']\n",
        "  #print(np.array(skel_class))\n",
        "  C_x.append(skel_class)\n",
        "  print(np.array(C_x).shape)\n",
        "  label_class=data['dataperclass'][c]['label_list']\n",
        "  C_y.append(label_class)\n",
        "  #print(len(C_y))\n",
        "  X.extend(skel_class)\n",
        "  Y.extend(label_class)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "follow\n",
            "(1, 500, 24)\n",
            "pour\n",
            "(2, 500, 24)\n",
            "pp\n",
            "(3, 500, 24)\n",
            "stand\n",
            "(4, 500, 24)\n",
            "stop\n",
            "(5, 500, 24)\n",
            "wave\n",
            "(6, 500, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpXYd8h8T5io",
        "outputId": "27345e1e-5928-4059-88a1-57ddee98368c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(np.array(X).shape)\n",
        "print(np.array(Y).shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3000, 24)\n",
            "(3000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NZKsVtpT_Ux"
      },
      "source": [
        "targets=[]\n",
        "for y in Y:\n",
        "  targets.append(y-1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt7-s4YRUCCX",
        "outputId": "18aa8841-454b-4f47-acdb-fd97ffab5dcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "encoder_Y = to_categorical(targets)\n",
        "print(Y[0], \": \", encoder_Y[0])\n",
        "print(Y[50], \": \", encoder_Y[50])\n",
        "print(Y[100], \": \", encoder_Y[100])\n",
        "print(Y[150], \": \", encoder_Y[150])\n",
        "print(Y[1000], \": \", encoder_Y[1000])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 :  [1. 0. 0. 0. 0. 0.]\n",
            "1 :  [1. 0. 0. 0. 0. 0.]\n",
            "1 :  [1. 0. 0. 0. 0. 0.]\n",
            "1 :  [1. 0. 0. 0. 0. 0.]\n",
            "3 :  [0. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgQgXqSiURWx"
      },
      "source": [
        "import numpy as np\n",
        "def train_test_split(X_data,Y_data,val=0.2,test=0.1):\n",
        "    X_data=np.array(X_data);Y_data=np.array(Y_data)\n",
        "    # create random train/test split\n",
        "    indices = list(range(X_data.shape[0]))\n",
        "    train_split=1.0-(val+test)\n",
        "    num_training_indices = int(train_split * X_data.shape[0])\n",
        "    num_valid_indices = int(val * X_data.shape[0])\n",
        "    #num_test_indices = int(train_split * X_data.shape[0])\n",
        "    np.random.shuffle(indices)\n",
        "    train_indices = indices[:num_training_indices]\n",
        "    valid_indices=indices[num_training_indices:num_training_indices+num_valid_indices]\n",
        "    test_indices = indices[num_training_indices+num_valid_indices:]\n",
        "\n",
        "    # split the actual data\n",
        "    X_data_train, X_data_val, X_data_test = X_data[train_indices], X_data[valid_indices], X_data[test_indices]\n",
        "    Y_data_train, Y_data_val ,Y_data_test = Y_data[train_indices], Y_data[valid_indices], Y_data[test_indices]\n",
        "    return (X_data_train, X_data_val, X_data_test, Y_data_train, Y_data_val, Y_data_test)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCYTD1irURkl"
      },
      "source": [
        "from tensorflow.keras.utils import normalize\n",
        "#from keras.preprocessing import timeseries_dataset_from_array\n",
        "X=normalize(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxczGPP3atTf"
      },
      "source": [
        "\n",
        "def batcher(l,y,n=10):\n",
        "  batches=[]\n",
        "  labels_b=[]\n",
        "  for i in range(0,len(l),1):\n",
        "    if (i<len(l)-n):\n",
        "      batches.append(l[i:n+i])\n",
        "      labels_b.append(y[i:n+i])\n",
        "  return batches,labels_b\n",
        "      #print(l[i:n+i])\n",
        "\n",
        "batches,labels_batches=batcher(X,encoder_Y) \n",
        "\n",
        "X_train, X_val, X_test, Y_train, Y_val, Y_test=train_test_split(batches,labels_batches)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9bzYL75eg6B",
        "outputId": "0699a2ec-f2b5-4a74-b30d-fe3610b14697",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2093, 10, 24)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2rGweuKespy"
      },
      "source": [
        "def build_model(input_shape):\n",
        "    \"\"\"Generates RNN-LSTM model\n",
        "    :param input_shape (tuple): Shape of input set\n",
        "    :return model: RNN-LSTM model\n",
        "    \"\"\"\n",
        "\n",
        "    # build network topology\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # 2 LSTM layers\n",
        "    model.add(keras.layers.LSTM(64, input_shape=input_shape, return_sequences=True))\n",
        "    model.add(keras.layers.LSTM(64))\n",
        "\n",
        "    # dense layer\n",
        "    model.add(keras.layers.Dense(64, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(0.3))\n",
        "\n",
        "    # output layer\n",
        "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OObNLkmzfUzb",
        "outputId": "28ba4192-8e27-4fc0-b375-905ced17ccfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model=build_model((10,24))\n",
        "model.summary()\n",
        "optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_8 (LSTM)                (None, 10, 64)            22784     \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 60,618\n",
            "Trainable params: 60,618\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8kcPMHGURlE",
        "outputId": "ed9000dc-3dda-44a1-8ffa-a7a13bb8641f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# batch_size: number of samples per gradient update\n",
        "# epochs: how many times to pass through the whole training set\n",
        "# verbose: show one line for every completed epoch\n",
        "history=model.fit(X_train, Y_train, batch_size=24, epochs=100, verbose=2, validation_data=(X_val, Y_val))\n",
        "#model.summary()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 2093 samples, validate on 598 samples\n",
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-62a9e1dd9d6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# epochs: how many times to pass through the whole training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# verbose: show one line for every completed epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#model.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: logits and labels must be broadcastable: logits_size=[24,10] labels_size=[144,10]\n\t [[{{node loss_2/dense_9_loss/softmax_cross_entropy_with_logits}}]]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dUIv_yPfC4u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}